{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 7e2737d] checkpoint\n",
      " 2 files changed, 408 insertions(+), 539 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git commit -a -m \"checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#パッケージのimport\" data-toc-modified-id=\"パッケージのimport-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>パッケージのimport</a></div><div class=\"lev1 toc-item\"><a href=\"#namedtuple\" data-toc-modified-id=\"namedtuple-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>namedtuple</a></div><div class=\"lev1 toc-item\"><a href=\"#定数の設定\" data-toc-modified-id=\"定数の設定-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>定数の設定</a></div><div class=\"lev1 toc-item\"><a href=\"#経験を保存するメモリクラスを定義します\" data-toc-modified-id=\"経験を保存するメモリクラスを定義します-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>経験を保存するメモリクラスを定義します</a></div><div class=\"lev2 toc-item\"><a href=\"#sandbox\" data-toc-modified-id=\"sandbox-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>sandbox</a></div><div class=\"lev1 toc-item\"><a href=\"#brainstorming\" data-toc-modified-id=\"brainstorming-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>brainstorming</a></div><div class=\"lev1 toc-item\"><a href=\"#Brain\" data-toc-modified-id=\"Brain-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Brain</a></div><div class=\"lev1 toc-item\"><a href=\"#Agent\" data-toc-modified-id=\"Agent-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Agent</a></div><div class=\"lev1 toc-item\"><a href=\"#pricer\" data-toc-modified-id=\"pricer-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>pricer</a></div><div class=\"lev2 toc-item\"><a href=\"#class-version-zero\" data-toc-modified-id=\"class-version-zero-81\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>class version zero</a></div><div class=\"lev1 toc-item\"><a href=\"#replacing-step()-and-state-initialization\" data-toc-modified-id=\"replacing-step()-and-state-initialization-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>replacing step() and state initialization</a></div><div class=\"lev2 toc-item\"><a href=\"#sandbox\" data-toc-modified-id=\"sandbox-91\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>sandbox</a></div><div class=\"lev1 toc-item\"><a href=\"#Environment改（大幅改修した）\" data-toc-modified-id=\"Environment改（大幅改修した）-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Environment改（大幅改修した）</a></div><div class=\"lev2 toc-item\"><a href=\"#Version-1\" data-toc-modified-id=\"Version-1-101\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Version 1</a></div><div class=\"lev3 toc-item\"><a href=\"#To-be-determined\" data-toc-modified-id=\"To-be-determined-1011\"><span class=\"toc-item-num\">10.1.1&nbsp;&nbsp;</span>To be determined</a></div><div class=\"lev3 toc-item\"><a href=\"#implementation\" data-toc-modified-id=\"implementation-1012\"><span class=\"toc-item-num\">10.1.2&nbsp;&nbsp;</span>implementation</a></div><div class=\"lev1 toc-item\"><a href=\"#predict\" data-toc-modified-id=\"predict-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>predict</a></div><div class=\"lev1 toc-item\"><a href=\"#sandbox\" data-toc-modified-id=\"sandbox-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>sandbox</a></div><div class=\"lev1 toc-item\"><a href=\"#参考（書籍のoriginal-Environment）\" data-toc-modified-id=\"参考（書籍のoriginal-Environment）-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>参考（書籍のoriginal Environment）</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** 5.3、5.4  PyTorchでDQN **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パッケージのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本コードでは、namedtupleを使用します。\n",
    "\n",
    "namedtupleを使うことで、値をフィールド名とペアで格納できます。\n",
    "\n",
    "すると値に対して、フィールド名でアクセスできて便利です。\n",
    "\n",
    "https://docs.python.jp/3/library/collections.html#collections.namedtuple\n",
    "\n",
    "以下は使用例です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr(name_a='名前Aです', value_b=100)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Tr = namedtuple('tr', ('name_a', 'value_b'))\n",
    "Tr_object = Tr('名前Aです', 100)\n",
    "\n",
    "print(Tr_object)  # 出力：tr(name_a='名前Aです', value_b=100)\n",
    "print(Tr_object.value_b)  # 出力：100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_object.name_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "namedtupleを生成\n",
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('s', 't', 'action', 'next_s' , \"next_t\", 'reward', 'done'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#namedtupleを生成\n",
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'action', 'next_state', 'reward'))#,'done'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_price = 127.62\n",
    "volatility = 0.20 # the historical vols or implied vols\n",
    "dividend_rate =  0.0163\n",
    "risk_free_rate = 0.001\n",
    "maturity = 1\n",
    "dt = 0.1\n",
    "\n",
    "strike_price = 130\n",
    "\n",
    "#steps = 200\n",
    "pricer_steps = 100\n",
    "\n",
    "#dt = maturity / steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENV = 'CartPole-v0'  # 使用する課題名\n",
    "GAMMA = np.exp(-dt * risk_free_rate)  # 時間割引率\n",
    "MAX_STEPS = 200  # 1試行のstep数\n",
    "#NUM_EPISODES = 500  # 最大試行回数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 経験を保存するメモリクラスを定義します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 概ね書籍のままの実装でいけるはず（？）$\\Rightarrow$ doneを追加した$\\Rightarrow$やっぱりやめた。（終了判定の方を変更するほうが素直なため）\n",
    "* ただし、おそらくサンプル取得時に完全にランダムにしないで3項ツリー的な３つのnext stateをまとめてmini batfchに含めたほうがいいのではないかという気がする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, CAPACITY):\n",
    "        self.capacity = CAPACITY  # メモリの最大長さ\n",
    "        self.memory = []  # 経験を保存する変数\n",
    "        self.index = 0  # 保存するindexを示す変数\n",
    "\n",
    "    def push(self, state, action, state_next, reward):# , done):\n",
    "        '''transition = (state, action, state_next, reward)をメモリに保存する'''\n",
    "\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)  # メモリが満タンでないときは足す\n",
    "\n",
    "        # namedtupleのTransitionを使用し、値とフィールド名をペアにして保存します\n",
    "        self.memory[self.index] = Transition(state, action, state_next, reward)# , done)\n",
    "\n",
    "        self.index = (self.index + 1) % self.capacity  # 保存するindexを1つずらす\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        '''batch_size分だけ、ランダムに保存内容を取り出す'''\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        '''関数lenに対して、現在の変数memoryの長さを返す'''\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ReplayMemory(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp.push(100,0.1, 0 , 101)#,  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brainstorming\n",
    "\n",
    "* 素直な実装ではnum_statesは２となる。（$S$および$t$）\n",
    "* brainもたぶん書籍のままの実装でいける？？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain\n",
    "\n",
    "エージェントが持つ脳となるクラスです、DQNを実行します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methodは\n",
    "\n",
    "* replay: Experience Replayでネットワークの結合パラメータを学習\n",
    "* decide_action: アクション決定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q関数をディープラーニングのネットワークをクラスとして定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CAPACITY = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* もともと次がdoneの場合は学習に使っていない.?と思ったがそんなことはなかった。\n",
    "* そのままだと学習が正しく進むわけがないので修正していく、というのは勘違いでここはいじらなくてよかった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.num_actions = num_actions  # CartPoleの行動（右に左に押す）の2を取得\n",
    "\n",
    "        # 経験を記憶するメモリオブジェクトを生成\n",
    "        self.memory = ReplayMemory(CAPACITY)\n",
    "\n",
    "        # ニューラルネットワークを構築\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('fc1', nn.Linear(num_states, 144))\n",
    "        self.model.add_module('relu1', nn.ReLU())\n",
    "        #self.model.add_module('fc2', nn.Linear(32, 32))\n",
    "        #self.model.add_module('relu2', nn.ReLU())\n",
    "        self.model.add_module('fc3', nn.Linear(144, num_actions))\n",
    "\n",
    "        print(self.model)  # ネットワークの形を出力\n",
    "        print(list(self.model.parameters()))\n",
    "\n",
    "        # 最適化手法の設定\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "\n",
    "    def replay(self):\n",
    "        '''Experience Replayでネットワークの結合パラメータを学習'''\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 1. メモリサイズの確認\n",
    "        # -----------------------------------------\n",
    "        # 1.1 メモリサイズがミニバッチより小さい間は何もしない\n",
    "        #print(\"memory .size : {}\".format(len(self.memory)))\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2. ミニバッチの作成\n",
    "        # -----------------------------------------\n",
    "        # 2.1 メモリからミニバッチ分のデータを取り出す\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        # 2.2 各変数をミニバッチに対応する形に変形\n",
    "        # transitionsは1stepごとの(state, action, state_next, reward)が、BATCH_SIZE分格納されている\n",
    "        # つまり、(state, action, state_next, reward)×BATCH_SIZE\n",
    "        # これをミニバッチにしたい。つまり\n",
    "        # (state×BATCH_SIZE, action×BATCH_SIZE, state_next×BATCH_SIZE, reward×BATCH_SIZE)にする\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # 2.3 各変数の要素をミニバッチに対応する形に変形し、ネットワークで扱えるようVariableにする\n",
    "        # 例えばstateの場合、[torch.FloatTensor of size 1x4]がBATCH_SIZE分並んでいるのですが、\n",
    "        # それを torch.FloatTensor of size BATCH_SIZEx4 に変換します\n",
    "        # 状態、行動、報酬、non_finalの状態のミニバッチのVariableを作成\n",
    "        # catはConcatenates（結合）のことです。\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        #done_batch = torch.cat(batch.done)\n",
    "        try:\n",
    "            non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                           if s is not None])\n",
    "        except:\n",
    "            print()\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 3. 教師信号となるQ(s_t, a_t)値を求める\n",
    "        # -----------------------------------------\n",
    "        # 3.1 ネットワークを推論モードに切り替える\n",
    "        self.model.eval()\n",
    "\n",
    "        # 3.2 ネットワークが出力したQ(s_t, a_t)を求める\n",
    "        # self.model(state_batch)は、右左の両方のQ値を出力しており\n",
    "        # [torch.FloatTensor of size BATCH_SIZEx2]になっている。\n",
    "        # ここから実行したアクションa_tに対応するQ値を求めるため、action_batchで行った行動a_tが右か左かのindexを求め\n",
    "        # それに対応するQ値をgatherでひっぱり出す。\n",
    "        state_action_values = self.model(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # 3.3 max{Q(s_t+1, a)}値を求める。ただし次の状態があるかに注意。\n",
    "\n",
    "        # cartpoleがdoneになっておらず、next_stateがあるかをチェックするインデックスマスクを作成\n",
    "        non_final_mask = torch.ByteTensor(tuple(map(lambda s: s is not None,\n",
    "                                                    batch.next_state)))\n",
    "        # まずは全部0にしておく\n",
    "        next_state_values = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "        # 次の状態があるindexの最大Q値を求める\n",
    "        # 出力にアクセスし、max(1)で列方向の最大値の[値、index]を求めます\n",
    "        # そしてそのQ値（index=0）を出力します\n",
    "        # detachでその値を取り出します\n",
    "        next_state_values[non_final_mask] = self.model(\n",
    "            non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "        # 3.4 教師となるQ(s_t, a_t)値を、Q学習の式から求める\n",
    "        expected_state_action_values = reward_batch + GAMMA * next_state_values\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 4. 結合パラメータの更新\n",
    "        # -----------------------------------------\n",
    "        # 4.1 ネットワークを訓練モードに切り替える\n",
    "        self.model.train()\n",
    "\n",
    "        # 4.2 損失関数を計算する（smooth_l1_lossはHuberloss）\n",
    "        # expected_state_action_valuesは\n",
    "        # sizeが[minbatch]になっているので、unsqueezeで[minibatch x 1]へ\n",
    "        loss = F.smooth_l1_loss(state_action_values,\n",
    "                                expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # 4.3 結合パラメータを更新する\n",
    "        self.optimizer.zero_grad()  # 勾配をリセット\n",
    "        loss.backward()  # バックプロパゲーションを計算\n",
    "        self.optimizer.step()  # 結合パラメータを更新\n",
    "\n",
    "    def decide_action(self, state, episode):\n",
    "        '''現在の状態に応じて、行動を決定する'''\n",
    "        # ε-greedy法で徐々に最適行動のみを採用する\n",
    "        epsilon = 0.5 * (1 / (episode + 1))\n",
    "\n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            self.model.eval()  # ネットワークを推論モードに切り替える\n",
    "            with torch.no_grad():\n",
    "                action = self.model(state).max(1)[1].view(1, 1)\n",
    "            # ネットワークの出力の最大値のindexを取り出します = max(1)[1]\n",
    "            # .view(1,1)は[torch.LongTensor of size 1]　を size 1x1 に変換します\n",
    "\n",
    "        else:\n",
    "            # 0,1の行動をランダムに返す\n",
    "            action = torch.LongTensor(\n",
    "                [[random.randrange(self.num_actions)]])  # 0,1の行動をランダムに返す\n",
    "            # actionは[torch.LongTensor of size 1x1]の形になります\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "CartPoleで動くエージェントクラスです、棒付き台車そのものになります\n",
    "\n",
    "methodは\n",
    "\n",
    "\n",
    "* 行動価値Qを更新\n",
    "*  状態を与えると行動を決定\n",
    "*  状態、選択するアクション、次の状態、報酬などを記憶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        '''課題の状態と行動の数を設定する'''\n",
    "        self.brain = Brain(num_states, num_actions)  # エージェントが行動を決定するための頭脳を生成\n",
    "\n",
    "    def update_q_function(self):\n",
    "        '''Q関数を更新する'''\n",
    "        self.brain.replay()\n",
    "\n",
    "    def get_action(self, state, episode):\n",
    "        '''行動を決定する'''\n",
    "        action = self.brain.decide_action(state, episode)\n",
    "        return action\n",
    "\n",
    "    def memorize(self, state, action, state_next, reward): #, done):\n",
    "        '''memoryオブジェクトに、state, action, state_next, rewardの内容を保存する'''\n",
    "        self.brain.memory.push(state, action, state_next, reward)# , done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pricer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import QuantLib as ql "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class version zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cl_am_call:\n",
    "    def price(self , spot_price, strike_price, maturity):\n",
    "        if maturity <= 0:\n",
    "            exercise_value = np.max([0 , spot_price - strike_price])\n",
    "            return (exercise_value)\n",
    "        dummy_strike = strike_price / spot_price\n",
    "        \n",
    "\n",
    "        option_type = ql.Option.Call\n",
    "        payoff = ql.PlainVanillaPayoff(option_type, dummy_strike)\n",
    "        \n",
    "        maturity_date = self.calculation_date + int(365.0 * maturity)\n",
    "        settlement = self.calculation_date\n",
    "        am_exercise = ql.AmericanExercise(settlement, maturity_date)\n",
    "        \n",
    "        american_option = ql.VanillaOption(payoff, am_exercise)\n",
    "        american_option.setPricingEngine(self.binomial_engine)\n",
    "        ql.Settings.instance().evaluationDate = self.calculation_date\n",
    "\n",
    "        return (american_option.NPV() * spot_price)\n",
    "        \n",
    "\n",
    "    def __init__(self , volatility , dividend_rate , risk_free_rate  ,steps):\n",
    "        day_count = ql.Actual365Fixed()\n",
    "        #calendar = ql.UnitedStates()\n",
    "        calendar = ql.Japan()\n",
    "        self.calculation_date = ql.Date(8, 5, 2015)\n",
    "        dummy_spot = 1\n",
    "        \n",
    "        self.spot_handle = ql.QuoteHandle(ql.SimpleQuote(1.0))\n",
    "\n",
    "        ql.Settings.instance().evaluationDate = self.calculation_date\n",
    "\n",
    "\n",
    "        self.flat_ts = ql.YieldTermStructureHandle(\n",
    "            ql.FlatForward(self.calculation_date, risk_free_rate, day_count)\n",
    "        )\n",
    "\n",
    "        self.dividend_yield = ql.YieldTermStructureHandle(\n",
    "            ql.FlatForward(self.calculation_date, dividend_rate, day_count)\n",
    "        )\n",
    "\n",
    "        #### volatility\n",
    "\n",
    "        self.flat_vol_ts = ql.BlackVolTermStructureHandle(\n",
    "            ql.BlackConstantVol(self.calculation_date, calendar, volatility, day_count)\n",
    "        )\n",
    "\n",
    "        #### BS framework\n",
    "\n",
    "        self.bsm_process = ql.BlackScholesMertonProcess(self.spot_handle, \n",
    "                                                   self.dividend_yield, \n",
    "                                                   self.flat_ts, \n",
    "                                                   self.flat_vol_ts)\n",
    "\n",
    "\n",
    "        self.binomial_engine = ql.BinomialVanillaEngine(self.bsm_process, \"crr\", steps)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call = cl_am_call(volatility ,  dividend_rate ,  risk_free_rate , pricer_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call.price(spot_price, strike_price, maturity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call.price(1 , 100, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replacing step() and state initialization\n",
    "\n",
    "* initializationをどうするかな・・\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  decision2next_state:\n",
    "    \n",
    "    def __init__(self ,  S0 , volatility , dividend_rate , risk_free_rate  , dt , Maturity):\n",
    "        self.S0 = S0\n",
    "        self.volatility = volatility\n",
    "        self.dividend_rate = dividend_rate\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.dt = dt\n",
    "        self.Maturity = Maturity\n",
    "        \n",
    "        self.barbeta_dt = (risk_free_rate - dividend_rate - volatility**2 * 0.5) * dt\n",
    "        self.sd = volatility * np.sqrt(dt)\n",
    "    \n",
    "    def reset(self):\n",
    "        T0 = 0    \n",
    "        if True:\n",
    "            state0 = np.array([self.S0 , T0])\n",
    "        else :\n",
    "            state0 = torch.Tensor(np.array([[self.S0 , T0]]))\n",
    "        return state0\n",
    "        \n",
    "    \n",
    "    def step(self , state , action):\n",
    "             #stateはtorch.tensor torch.Size([1, 2])\n",
    "            if False:\n",
    "                #next_state = state.copy()\n",
    "                S = state[0]\n",
    "                T = state[1]\n",
    "            else:               \n",
    "                #next_state = state.clone()\n",
    "                S = state[0][0].item()\n",
    "                T = state[0][1].item()    \n",
    "            T_next = T + self.dt\n",
    "            S_return = self.barbeta_dt + self.sd * np.random.randn()  \n",
    "            \n",
    "            S_next = S * np.exp(S_return)\n",
    "            if True:\n",
    "                state_next =np.array([S_next , T_next])\n",
    "            else:\n",
    "                state_next = torch.Tensor(np.array([[S_next , T_next]]))\n",
    "            done = (action == 1) or (T >= self.Maturity) \n",
    "            if done:\n",
    "                S_next = None\n",
    "            return state_next , done\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stepper = decision2next_state(spot_price, volatility , dividend_rate , risk_free_rate , 0.1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_state = torch.Tensor(np.array([[100 , 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_state = np.array([100,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stepper.step(tmp_state , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stepper.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment改（大幅改修した）\n",
    "CartPoleを実行する環境のクラスです\n",
    "\n",
    "* for loopは二重になっている\n",
    "* 外側のループはEPISODEに関して\n",
    "    * Episode = 試行：一回ポールを立てて倒れるか200ステップ経過するまでを１エピソードと数える\n",
    "    * 内側のループはステップに関して\n",
    "        * 初期状態のBrainを使って、1ステップ目から左右にコントロールしていくことからスタート\n",
    "        * 各ステップごとに状態と遷移を記録する。\n",
    "        * 同様に各ステップごとに行動価値関数をアップデートしていく\n",
    "    * 10エピソード連続で200ステップまで持ちこたえられたら成功\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1\n",
    "* まずはMCパスを発生させて、episode $\\approx$ pathであるような形でやってみよう\n",
    "* 後々、MCパスはtrinomial tree上のみを推移するようにするかもしれないが、ここでは素直にMCパスを普通に発生させてみよう\n",
    "    * MCパス発生はquantlibにやらせてもいいが自分で実装してしまってもいいかな\n",
    "* env.stepを\n",
    "```\n",
    " 1 time step推進\n",
    "```\n",
    "に置き換える。\n",
    "\n",
    "\n",
    "### To be determined\n",
    "* QLはここに取り込む？ $\\Rightarrow$ maybe yes\n",
    "* MCもここで？ $\\Rightarrow$ maybe yes\n",
    "    * gymの場合は時間推進はgymが面倒見てくれていた。そのgymはEnvironmentクラスのメンバーになっている。\n",
    "* 書籍にあったような20回連続でみたいな終了判定基準はもはや適切ではない。ではどのような終了判定基準が良いか\n",
    "```\n",
    "現状では正解がわかっているのでいろいろズルをしよう。例えば、10パス連続で最適行使の判定を正解できたときetc\n",
    "```\n",
    "* reward設計\n",
    "```\n",
    "行使した場合にはrewardを払って行動価値関数がゼロのnext stateに飛ぶ\n",
    "```\n",
    "とする."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import QuantLib as ql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myEnvironment:\n",
    "\n",
    "    def __init__(self, S0 , vol , q , r , K , T , dt ,pricer_steps):\n",
    "        #self.env = gym.make(ENV)  # 実行する課題を設定\n",
    "        self.S0 = S0\n",
    "        self.vol = vol\n",
    "        self.q = q\n",
    "        self.r = r\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.stepper = decision2next_state(S0 , vol , q , r , dt, T)\n",
    "        \n",
    "        num_states = 2# S and t\n",
    "        num_actions = 2 # exercise or hold \n",
    "        self.agent = Agent(num_states, num_actions)  # 環境内で行動するAgentを生成\n",
    "        self.pricer = cl_am_call(vol ,  q ,  r , steps = pricer_steps)\n",
    "\n",
    "        \n",
    "    def run(self , n_episodes , is_silent = False):\n",
    "        '''実行'''\n",
    "        episode_10_list = np.zeros(10)  # 10試行分の立ち続けたstep数を格納し、平均ステップ数を出力に利用\n",
    "        #complete episodesを終了条件にするのはもはや適切ではない\n",
    "        complete_episodes = 0  # 195step以上連続で立ち続けた試行数\n",
    "        episode_final = False  # 最後の試行フラグ\n",
    "        frames = []  # 最後の試行を動画にするために画像を格納する変数\n",
    "\n",
    "        for episode in range(n_episodes):  # 最大試行数分繰り返す\n",
    "            #observation = self.env.reset()  # 環境の初期化\n",
    "            observation = self.stepper.reset()\n",
    "            if episode % 200 == 0:\n",
    "                print(\"finished {} episodes\".format(episode))\n",
    "\n",
    "            state = observation  # 観測をそのまま状態sとして使用\n",
    "            if True:\n",
    "                #print(type(state))\n",
    "                state = torch.from_numpy(state).type(torch.FloatTensor)  # NumPy変数をPyTorchのテンソルに変換\n",
    "                state = torch.unsqueeze(state, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "            for step in range(MAX_STEPS):  # 1エピソードのループ\n",
    "\n",
    "                action = self.agent.get_action(state, episode)  # 行動を求める。\n",
    "                ### * episodeを食わせるのはQ学習の定義を見れば納得できる。ここは書籍のままの\n",
    "        \n",
    "                \n",
    "                # 行動a_tの実行により、s_{t+1}とdoneフラグを求める\n",
    "                # actionから.item()を指定して、中身を取り出す\n",
    " \n",
    "                observation_next , done = self.stepper.step(state , action.item())\n",
    "                #print(\"done is {}\".format(done))\n",
    "\n",
    "                # 報酬を与える。さらにepisodeの終了評価と、state_nextを設定する\n",
    "                if done:  # ステップ数が200経過するか、一定角度以上傾くとdoneはtrueになる\n",
    "                    state_next = None  # 次の状態はないので、Noneを格納\n",
    "       \n",
    "\n",
    "                    # 直近10episodeの立てたstep数リストに追加\n",
    "                    episode_10_list = np.hstack(\n",
    "                        (episode_10_list[1:], step + 1))\n",
    "                    if True:\n",
    "                        exercise_value = state[0][0].item() - self.K   \n",
    "                        if state[0][1].item() >= self.T:\n",
    "                            exercise_value = np.max([exercise_value , 0.0])\n",
    "                        \n",
    "                        reward = torch.FloatTensor([exercise_value]) \n",
    "                        complete_episodes = complete_episodes + 1  ## * 暫定的な処理\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    reward = torch.FloatTensor([0.0])  # 普段は報酬0\n",
    "                    state_next = observation_next  # 観測をそのまま状態とする\n",
    "                    if True:\n",
    "                        state_next = torch.from_numpy(state_next).type(\n",
    "                        torch.FloatTensor)  # numpy変数をPyTorchのテンソルに変換\n",
    "                        state_next = torch.unsqueeze(state_next, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "                # メモリに経験を追加\n",
    "                self.agent.memorize(state, action, state_next, reward)\n",
    "\n",
    "                # Experience ReplayでQ関数を更新する\n",
    "                try:\n",
    "                    self.agent.update_q_function()\n",
    "                except:\n",
    "                    print(\"something is wrong\")\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "                # 終了時の処理\n",
    "                if done:\n",
    "                    #print('%d Episode: Finished after %d steps：10試行の平均step数 = %.1lf' % (\n",
    "                    #    episode, step + 1, episode_10_list.mean()))\n",
    "                    #print(\"exercise value is {}\".format(exercise_value))\n",
    "                    #print(type(state))\n",
    "\n",
    "                    error = exercise_value - self.pricer.price(state[0][0].item(), self.K , self.T - state[0][1].item())\n",
    "                    if not is_silent:\n",
    "                        print(\"S : {:.2f} / t : {:.2f} / exercise value : {:.2f} / error : {:.2f}\".format(state[0][0].item() , state[0][1].item() , exercise_value , error))\n",
    "                    break\n",
    "                    ## ** error \n",
    "                                # 観測の更新\n",
    "                state = state_next\n",
    "            if episode_final:\n",
    "                break\n",
    "\n",
    "            # 10連続で200step経ち続けたら成功\n",
    "            if complete_episodes >= n_episodes:\n",
    "                #print('10回連続成功')\n",
    "                episode_final = True  # 次の試行を描画を行う最終試行とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=2, out_features=144, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc3): Linear(in_features=144, out_features=2, bias=True)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[-0.3119, -0.5382],\n",
      "        [-0.4344,  0.5550],\n",
      "        [-0.2473, -0.1746],\n",
      "        [-0.6260,  0.0306],\n",
      "        [-0.0105,  0.4903],\n",
      "        [-0.6760,  0.5389],\n",
      "        [-0.2231,  0.2125],\n",
      "        [-0.5439,  0.1630],\n",
      "        [-0.5913, -0.2761],\n",
      "        [-0.2001,  0.0714],\n",
      "        [-0.6156,  0.5958],\n",
      "        [ 0.2385, -0.3333],\n",
      "        [ 0.3717, -0.2409],\n",
      "        [ 0.0275, -0.5031],\n",
      "        [-0.6040,  0.0507],\n",
      "        [ 0.5773,  0.2617],\n",
      "        [ 0.2922, -0.0060],\n",
      "        [ 0.3158, -0.1131],\n",
      "        [ 0.4119, -0.3197],\n",
      "        [ 0.3909, -0.6006],\n",
      "        [-0.3897,  0.6455],\n",
      "        [-0.4864,  0.2845],\n",
      "        [-0.6781, -0.3104],\n",
      "        [ 0.5674, -0.2551],\n",
      "        [ 0.2898,  0.1906],\n",
      "        [ 0.6830, -0.1614],\n",
      "        [-0.5107,  0.6681],\n",
      "        [ 0.0588,  0.0277],\n",
      "        [-0.1821, -0.1704],\n",
      "        [ 0.3414, -0.4880],\n",
      "        [-0.0569,  0.3467],\n",
      "        [-0.3734,  0.3153],\n",
      "        [ 0.4085, -0.3659],\n",
      "        [ 0.0370,  0.2351],\n",
      "        [-0.4535,  0.4971],\n",
      "        [ 0.2386, -0.3200],\n",
      "        [ 0.4184,  0.3797],\n",
      "        [ 0.6645,  0.4843],\n",
      "        [-0.3680, -0.4528],\n",
      "        [ 0.6845,  0.5259],\n",
      "        [-0.6984,  0.2485],\n",
      "        [ 0.2615,  0.1558],\n",
      "        [-0.4379, -0.7067],\n",
      "        [ 0.6459, -0.0684],\n",
      "        [ 0.3492,  0.0554],\n",
      "        [-0.5678, -0.6124],\n",
      "        [ 0.1593,  0.5956],\n",
      "        [-0.3636, -0.5575],\n",
      "        [-0.6851,  0.5175],\n",
      "        [ 0.2264,  0.2237],\n",
      "        [-0.3901, -0.4011],\n",
      "        [ 0.4252, -0.2666],\n",
      "        [ 0.3293,  0.3124],\n",
      "        [-0.1175, -0.5463],\n",
      "        [-0.2664,  0.1203],\n",
      "        [-0.5702,  0.4731],\n",
      "        [-0.0724, -0.6094],\n",
      "        [ 0.1078,  0.0547],\n",
      "        [ 0.7044,  0.2398],\n",
      "        [-0.6923, -0.3526],\n",
      "        [ 0.3908, -0.4267],\n",
      "        [ 0.6007, -0.5430],\n",
      "        [ 0.2171, -0.2131],\n",
      "        [-0.3170,  0.1896],\n",
      "        [ 0.3942, -0.6494],\n",
      "        [-0.0077, -0.3672],\n",
      "        [ 0.0236,  0.0934],\n",
      "        [ 0.0990, -0.2844],\n",
      "        [ 0.1401, -0.0670],\n",
      "        [-0.5082, -0.2412],\n",
      "        [ 0.5126, -0.6255],\n",
      "        [ 0.6158, -0.6948],\n",
      "        [ 0.5813, -0.3843],\n",
      "        [ 0.0029,  0.0290],\n",
      "        [-0.3461,  0.0092],\n",
      "        [ 0.4868, -0.6661],\n",
      "        [-0.1753, -0.6846],\n",
      "        [-0.5194,  0.2680],\n",
      "        [-0.0866,  0.0841],\n",
      "        [-0.4425, -0.1963],\n",
      "        [-0.5144,  0.1130],\n",
      "        [-0.5642,  0.3616],\n",
      "        [-0.4384, -0.0724],\n",
      "        [ 0.6829,  0.2778],\n",
      "        [ 0.3831, -0.5502],\n",
      "        [-0.6813,  0.1771],\n",
      "        [-0.5771,  0.2805],\n",
      "        [ 0.5116,  0.6520],\n",
      "        [ 0.2310, -0.0723],\n",
      "        [-0.4873,  0.1698],\n",
      "        [-0.6879, -0.0436],\n",
      "        [ 0.0461,  0.4293],\n",
      "        [-0.5331, -0.4356],\n",
      "        [ 0.1179,  0.1165],\n",
      "        [-0.2483, -0.7022],\n",
      "        [-0.2254,  0.1096],\n",
      "        [ 0.6894,  0.2642],\n",
      "        [ 0.6909, -0.2757],\n",
      "        [-0.4640, -0.1900],\n",
      "        [-0.1108, -0.1961],\n",
      "        [ 0.0347, -0.6326],\n",
      "        [-0.3874, -0.4042],\n",
      "        [ 0.3661, -0.0241],\n",
      "        [ 0.0169,  0.1757],\n",
      "        [-0.4314, -0.3622],\n",
      "        [-0.1921, -0.1227],\n",
      "        [-0.4690,  0.6862],\n",
      "        [-0.6682, -0.2093],\n",
      "        [ 0.4192, -0.1070],\n",
      "        [ 0.4020,  0.0959],\n",
      "        [ 0.3621, -0.3969],\n",
      "        [-0.2608, -0.6585],\n",
      "        [ 0.1500, -0.1041],\n",
      "        [-0.0100,  0.0340],\n",
      "        [-0.2637,  0.0791],\n",
      "        [ 0.0356, -0.4088],\n",
      "        [ 0.5273, -0.0521],\n",
      "        [ 0.2080,  0.1493],\n",
      "        [ 0.0045,  0.4882],\n",
      "        [ 0.0979,  0.3893],\n",
      "        [-0.2832, -0.3444],\n",
      "        [-0.5371, -0.6645],\n",
      "        [-0.5870,  0.5448],\n",
      "        [-0.1772, -0.2884],\n",
      "        [-0.5660, -0.1056],\n",
      "        [ 0.4208,  0.2913],\n",
      "        [ 0.0220, -0.2916],\n",
      "        [-0.5598, -0.3097],\n",
      "        [-0.0106,  0.5366],\n",
      "        [-0.3457,  0.2144],\n",
      "        [-0.6883, -0.5391],\n",
      "        [-0.5645,  0.2619],\n",
      "        [-0.3411,  0.5831],\n",
      "        [-0.6064, -0.5194],\n",
      "        [-0.6618, -0.6827],\n",
      "        [ 0.2895,  0.5139],\n",
      "        [-0.4979, -0.2244],\n",
      "        [-0.5401,  0.3506],\n",
      "        [ 0.6045,  0.3581],\n",
      "        [-0.4674, -0.6198],\n",
      "        [-0.0076,  0.5782],\n",
      "        [ 0.2249,  0.3203],\n",
      "        [ 0.0474, -0.5685],\n",
      "        [-0.1140, -0.1550]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3264, -0.3821, -0.0685,  0.3138, -0.4152, -0.0135, -0.5898, -0.3738,\n",
      "         0.2111, -0.3331, -0.3274,  0.4791,  0.0002,  0.3702,  0.0221, -0.6681,\n",
      "         0.1338,  0.6765,  0.3617,  0.1020, -0.2485, -0.2051, -0.5432,  0.3441,\n",
      "         0.1870,  0.6114,  0.2083, -0.1152,  0.6645,  0.4012, -0.6628, -0.0573,\n",
      "        -0.2598, -0.6498,  0.2786, -0.4051,  0.0208, -0.6744,  0.3959, -0.6386,\n",
      "        -0.4994, -0.5866, -0.0986, -0.1878, -0.2110, -0.2044,  0.2812,  0.4074,\n",
      "        -0.5274,  0.2842, -0.2958,  0.2346, -0.6177,  0.6252, -0.6855,  0.2722,\n",
      "         0.1502, -0.3197, -0.2464, -0.3242,  0.6233,  0.2355, -0.2599, -0.2601,\n",
      "         0.1598, -0.4960,  0.4467, -0.3443, -0.0778, -0.6756, -0.5143,  0.3947,\n",
      "        -0.7053, -0.6109,  0.0663,  0.5970,  0.4107, -0.3005, -0.1890,  0.1669,\n",
      "        -0.5958, -0.4850,  0.0363, -0.1762, -0.3908,  0.6065,  0.2882,  0.3933,\n",
      "         0.2510, -0.5938,  0.4266,  0.4193, -0.6787,  0.4271, -0.3053, -0.0458,\n",
      "         0.7010,  0.2404, -0.3936,  0.2132, -0.0095,  0.1961, -0.3906, -0.6960,\n",
      "         0.6407, -0.3622,  0.4233, -0.5829, -0.4047, -0.4506,  0.5281,  0.4374,\n",
      "        -0.4918, -0.0138, -0.4903,  0.2640, -0.4781, -0.4828,  0.1430,  0.2590,\n",
      "        -0.5170, -0.0771, -0.1931,  0.3520,  0.3534, -0.6169, -0.6143, -0.5946,\n",
      "         0.6556, -0.1829, -0.5898,  0.2735, -0.3952, -0.2871, -0.3998,  0.4741,\n",
      "         0.4373, -0.2405,  0.0203,  0.3577, -0.5240,  0.4959,  0.6098, -0.4320],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0606, -0.0527, -0.0117, -0.0331,  0.0010, -0.0805, -0.0267,  0.0465,\n",
      "         -0.0673, -0.0198,  0.0557, -0.0704,  0.0010, -0.0758, -0.0528, -0.0317,\n",
      "         -0.0278,  0.0474,  0.0334, -0.0102,  0.0631,  0.0099,  0.0314, -0.0773,\n",
      "          0.0654,  0.0243, -0.0100, -0.0219,  0.0099, -0.0418,  0.0001,  0.0468,\n",
      "          0.0503,  0.0384, -0.0705, -0.0010, -0.0178,  0.0806, -0.0700,  0.0550,\n",
      "          0.0317, -0.0280,  0.0026,  0.0551,  0.0769,  0.0143, -0.0097,  0.0737,\n",
      "          0.0751, -0.0257,  0.0480,  0.0808, -0.0438,  0.0785,  0.0213,  0.0429,\n",
      "         -0.0749,  0.0066,  0.0317, -0.0127, -0.0387,  0.0033,  0.0726,  0.0088,\n",
      "         -0.0642,  0.0058,  0.0076,  0.0124, -0.0152,  0.0538,  0.0700,  0.0272,\n",
      "         -0.0126,  0.0398,  0.0575,  0.0784,  0.0453, -0.0532,  0.0344, -0.0618,\n",
      "         -0.0423, -0.0176, -0.0550,  0.0029,  0.0725, -0.0651, -0.0262,  0.0060,\n",
      "          0.0786,  0.0473, -0.0401,  0.0409,  0.0799, -0.0535, -0.0069,  0.0766,\n",
      "          0.0519, -0.0235,  0.0243, -0.0238,  0.0440, -0.0496,  0.0119, -0.0255,\n",
      "         -0.0380, -0.0231, -0.0750, -0.0519,  0.0362,  0.0339, -0.0719,  0.0332,\n",
      "         -0.0009,  0.0584,  0.0705, -0.0752,  0.0488,  0.0819,  0.0166,  0.0708,\n",
      "          0.0003, -0.0560,  0.0598,  0.0247, -0.0831, -0.0340, -0.0432, -0.0685,\n",
      "          0.0767, -0.0301, -0.0658,  0.0743,  0.0333, -0.0325,  0.0693,  0.0537,\n",
      "         -0.0498, -0.0260,  0.0507, -0.0023, -0.0142,  0.0478, -0.0654,  0.0808],\n",
      "        [ 0.0826,  0.0493, -0.0805,  0.0007,  0.0783,  0.0250,  0.0136, -0.0099,\n",
      "         -0.0233, -0.0664,  0.0145,  0.0459, -0.0299, -0.0820, -0.0687, -0.0562,\n",
      "          0.0629,  0.0678,  0.0690, -0.0290, -0.0608,  0.0445, -0.0373, -0.0075,\n",
      "          0.0542, -0.0487,  0.0035, -0.0254,  0.0784,  0.0600, -0.0737, -0.0617,\n",
      "          0.0043, -0.0275, -0.0335, -0.0530, -0.0268, -0.0070, -0.0452,  0.0175,\n",
      "         -0.0317,  0.0787, -0.0031,  0.0112,  0.0431, -0.0083,  0.0321, -0.0094,\n",
      "          0.0187, -0.0082,  0.0754,  0.0686,  0.0721, -0.0754,  0.0096, -0.0354,\n",
      "         -0.0147, -0.0337, -0.0353,  0.0569,  0.0809,  0.0128,  0.0358,  0.0693,\n",
      "         -0.0820,  0.0509,  0.0047,  0.0156,  0.0566,  0.0573,  0.0661,  0.0054,\n",
      "         -0.0552,  0.0655,  0.0391,  0.0139, -0.0665,  0.0444, -0.0117, -0.0745,\n",
      "          0.0243,  0.0825,  0.0655,  0.0320,  0.0718, -0.0391,  0.0412,  0.0821,\n",
      "         -0.0618, -0.0675,  0.0466, -0.0107,  0.0329, -0.0261, -0.0300, -0.0622,\n",
      "          0.0692,  0.0307,  0.0217,  0.0548, -0.0681, -0.0718,  0.0707,  0.0543,\n",
      "          0.0215, -0.0334, -0.0745,  0.0167, -0.0045, -0.0166,  0.0504, -0.0757,\n",
      "         -0.0009, -0.0687,  0.0414, -0.0131, -0.0013, -0.0568, -0.0715, -0.0569,\n",
      "         -0.0385, -0.0410, -0.0670,  0.0310,  0.0030,  0.0449, -0.0519,  0.0391,\n",
      "          0.0453, -0.0828,  0.0203, -0.0552, -0.0331, -0.0253, -0.0663, -0.0286,\n",
      "         -0.0517,  0.0008,  0.0420,  0.0517, -0.0286,  0.0497,  0.0328,  0.0257]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0670, -0.0223], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# main クラス\n",
    "cartpole_env = myEnvironment(spot_price , volatility , dividend_rate , risk_free_rate , strike_price , maturity , dt , pricer_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0 episodes\n",
      "S : 141.79 / t : 0.40 / exercise value : 11.79 / error : -3.05\n",
      "S : 129.92 / t : 0.20 / exercise value : -0.08 / error : -8.57\n",
      "S : 123.21 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 142.39 / t : 1.00 / exercise value : 12.39 / error : 0.00\n",
      "S : 126.05 / t : 0.80 / exercise value : -3.95 / error : -6.66\n",
      "S : 123.94 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 134.89 / t : 1.00 / exercise value : 4.89 / error : 0.00\n",
      "S : 137.04 / t : 1.00 / exercise value : 7.04 / error : 0.00\n",
      "S : 128.70 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 109.47 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 133.78 / t : 0.60 / exercise value : 3.78 / error : -4.50\n",
      "S : 146.13 / t : 1.00 / exercise value : 16.13 / error : 0.00\n",
      "S : 146.73 / t : 1.00 / exercise value : 16.73 / error : 0.00\n",
      "S : 106.38 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 122.30 / t : 0.40 / exercise value : -7.70 / error : -11.84\n",
      "S : 100.40 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 121.48 / t : 0.10 / exercise value : -8.52 / error : -13.80\n",
      "S : 119.69 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 155.31 / t : 1.00 / exercise value : 25.31 / error : 0.00\n",
      "S : 94.63 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 111.57 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 148.20 / t : 1.00 / exercise value : 18.20 / error : 0.00\n",
      "S : 123.02 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 95.07 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 151.36 / t : 1.00 / exercise value : 21.36 / error : 0.00\n",
      "S : 104.06 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 144.72 / t : 1.00 / exercise value : 14.72 / error : 0.00\n",
      "S : 104.54 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 117.36 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 127.62 / t : 0.00 / exercise value : -2.38 / error : -10.71\n",
      "S : 81.39 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 93.26 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 113.68 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 111.92 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 131.93 / t : 1.00 / exercise value : 1.93 / error : 0.00\n",
      "S : 102.12 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 109.37 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 93.89 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 88.85 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 118.44 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 111.96 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 150.76 / t : 1.00 / exercise value : 20.76 / error : 0.00\n",
      "S : 129.63 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 109.62 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 151.91 / t : 1.00 / exercise value : 21.91 / error : 0.00\n",
      "S : 128.79 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 122.04 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 149.95 / t : 1.00 / exercise value : 19.95 / error : 0.00\n",
      "S : 99.70 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 100.07 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 152.80 / t : 1.00 / exercise value : 22.80 / error : 0.00\n",
      "S : 136.30 / t : 1.00 / exercise value : 6.30 / error : 0.00\n",
      "S : 158.28 / t : 1.00 / exercise value : 28.28 / error : 0.00\n",
      "S : 151.71 / t : 1.00 / exercise value : 21.71 / error : 0.00\n",
      "S : 147.41 / t : 0.40 / exercise value : 17.41 / error : -1.76\n",
      "S : 106.57 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 142.96 / t : 1.00 / exercise value : 12.96 / error : 0.00\n",
      "S : 150.38 / t : 1.00 / exercise value : 20.38 / error : 0.00\n",
      "S : 120.32 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 131.69 / t : 1.00 / exercise value : 1.69 / error : 0.00\n",
      "S : 167.93 / t : 1.00 / exercise value : 37.93 / error : 0.00\n",
      "S : 105.14 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 167.07 / t : 0.70 / exercise value : 37.07 / error : 0.00\n",
      "S : 127.62 / t : 0.00 / exercise value : -2.38 / error : -10.71\n",
      "S : 127.62 / t : 0.00 / exercise value : -2.38 / error : -10.71\n",
      "S : 127.62 / t : 0.00 / exercise value : -2.38 / error : -10.71\n",
      "S : 127.62 / t : 0.00 / exercise value : -2.38 / error : -10.71\n",
      "S : 127.62 / t : 0.00 / exercise value : -2.38 / error : -10.71\n",
      "S : 137.94 / t : 1.00 / exercise value : 7.94 / error : 0.00\n",
      "S : 101.72 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 163.76 / t : 1.00 / exercise value : 33.76 / error : 0.00\n",
      "S : 122.83 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 147.35 / t : 1.00 / exercise value : 17.35 / error : 0.00\n",
      "S : 103.96 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 102.80 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 129.38 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 166.23 / t : 1.00 / exercise value : 36.23 / error : 0.00\n",
      "S : 126.98 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 127.90 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 102.17 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 165.47 / t : 1.00 / exercise value : 35.47 / error : 0.00\n",
      "S : 142.44 / t : 1.00 / exercise value : 12.44 / error : 0.00\n",
      "S : 140.48 / t : 1.00 / exercise value : 10.48 / error : 0.00\n",
      "S : 109.68 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 131.56 / t : 1.00 / exercise value : 1.56 / error : 0.00\n",
      "S : 146.41 / t : 1.00 / exercise value : 16.41 / error : 0.00\n",
      "S : 90.80 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 165.16 / t : 1.00 / exercise value : 35.16 / error : 0.00\n",
      "S : 116.88 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 101.90 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 119.90 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 121.65 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 159.82 / t : 1.00 / exercise value : 29.82 / error : 0.00\n",
      "S : 92.43 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 95.82 / t : 1.00 / exercise value : 0.00 / error : 0.00\n",
      "S : 116.46 / t : 0.80 / exercise value : -13.54 / error : -14.06\n",
      "S : 131.12 / t : 1.00 / exercise value : 1.12 / error : 0.00\n",
      "S : 137.83 / t : 1.00 / exercise value : 7.83 / error : 0.00\n",
      "S : 174.97 / t : 1.00 / exercise value : 44.97 / error : 0.00\n",
      "S : 171.28 / t : 1.00 / exercise value : 41.28 / error : 0.00\n"
     ]
    }
   ],
   "source": [
    "cartpole_env.run(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0 episodes\n",
      "finished 200 episodes\n",
      "finished 400 episodes\n",
      "finished 600 episodes\n",
      "finished 800 episodes\n",
      "finished 1000 episodes\n",
      "finished 1200 episodes\n",
      "finished 1400 episodes\n",
      "finished 1600 episodes\n",
      "finished 1800 episodes\n",
      "finished 2000 episodes\n",
      "finished 2200 episodes\n",
      "finished 2400 episodes\n",
      "finished 2600 episodes\n",
      "finished 2800 episodes\n",
      "finished 3000 episodes\n",
      "finished 3200 episodes\n",
      "finished 3400 episodes\n",
      "finished 3600 episodes\n",
      "finished 3800 episodes\n",
      "finished 4000 episodes\n",
      "finished 4200 episodes\n",
      "finished 4400 episodes\n",
      "finished 4600 episodes\n",
      "finished 4800 episodes\n",
      "finished 5000 episodes\n",
      "finished 5200 episodes\n",
      "finished 5400 episodes\n",
      "finished 5600 episodes\n",
      "finished 5800 episodes\n",
      "finished 6000 episodes\n",
      "finished 6200 episodes\n",
      "finished 6400 episodes\n",
      "finished 6600 episodes\n",
      "finished 6800 episodes\n",
      "finished 7000 episodes\n",
      "finished 7200 episodes\n",
      "finished 7400 episodes\n",
      "finished 7600 episodes\n",
      "finished 7800 episodes\n",
      "finished 8000 episodes\n",
      "finished 8200 episodes\n",
      "finished 8400 episodes\n",
      "finished 8600 episodes\n",
      "finished 8800 episodes\n",
      "finished 9000 episodes\n",
      "finished 9200 episodes\n",
      "finished 9400 episodes\n",
      "finished 9600 episodes\n",
      "finished 9800 episodes\n"
     ]
    }
   ],
   "source": [
    "cartpole_env.run(10000, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cartpole_env.agent.brain.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=2, out_features=144, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc3): Linear(in_features=144, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_underliers = [float(i) * 10 for i in range(1 , 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_input = torch.tensor([\n",
    "    [s , 0.] for s in run_underliers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_input = torch.tensor([100.0 ,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_outputs = model(run_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.2335,  -3.2294],\n",
       "        [ -5.6955,  -5.6876],\n",
       "        [ -5.1107,  -8.1453],\n",
       "        [ -4.4895, -10.6140],\n",
       "        [ -3.8511, -13.0900],\n",
       "        [ -3.1860, -15.5673],\n",
       "        [ -2.4345, -18.0493],\n",
       "        [ -1.6831, -20.5313],\n",
       "        [ -0.9317, -23.0133],\n",
       "        [ -0.1205, -25.4886],\n",
       "        [  0.7098, -27.9617],\n",
       "        [  1.8575, -30.4015],\n",
       "        [  3.1107, -32.8301],\n",
       "        [  4.3640, -35.2587],\n",
       "        [  5.6173, -37.6873],\n",
       "        [  6.8706, -40.1160],\n",
       "        [  8.1239, -42.5446],\n",
       "        [  9.3772, -44.9732],\n",
       "        [ 10.6304, -47.4018]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame({\"underlier\" : run_underliers, \n",
    "              \"value0\" : [x.item() for x in run_outputs[:,0]]  , \n",
    "              \"value1\" : [x.item() for x in run_outputs[:,1]] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1cafcb4e-12cd-443a-9181-105306097845\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1cafcb4e-12cd-443a-9181-105306097845\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1cafcb4e-12cd-443a-9181-105306097845\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1cafcb4e-12cd-443a-9181-105306097845' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1cafcb4e-12cd-443a-9181-105306097845\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1cafcb4e-12cd-443a-9181-105306097845\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1cafcb4e-12cd-443a-9181-105306097845\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1cafcb4e-12cd-443a-9181-105306097845' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1cafcb4e-12cd-443a-9181-105306097845\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh import palettes\n",
    "bp.output_notebook()\n",
    "from bokeh.models import ColumnDataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.renderers.GlyphRenderer\">GlyphRenderer</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'3be9dad8-566a-43e7-b819-0f3603725886', <span id=\"dacfe850-2c9c-44af-85af-e2c446b09aa8\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">data_source&nbsp;=&nbsp;ColumnDataSource(id='794ce520-b858-49d8-9348-64c2020aa2ca', ...),</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">glyph&nbsp;=&nbsp;Circle(id='e2406238-b7b7-4d11-9c94-db89fc1879f5', ...),</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hover_glyph&nbsp;=&nbsp;None,</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">level&nbsp;=&nbsp;'glyph',</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted&nbsp;=&nbsp;False,</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted_glyph&nbsp;=&nbsp;None,</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">nonselection_glyph&nbsp;=&nbsp;Circle(id='5f59a90c-ab1e-4299-9f62-adfc82cea8d4', ...),</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">selection_glyph&nbsp;=&nbsp;None,</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">view&nbsp;=&nbsp;CDSView(id='93a5a994-f1a9-4efb-80ce-15947321a003', ...),</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range_name&nbsp;=&nbsp;'default',</div></div><div class=\"7cd91f87-5179-4bff-abf6-ff4b620337c8\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range_name&nbsp;=&nbsp;'default')</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"dacfe850-2c9c-44af-85af-e2c446b09aa8\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"7cd91f87-5179-4bff-abf6-ff4b620337c8\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "GlyphRenderer(id='3be9dad8-566a-43e7-b819-0f3603725886', ...)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.scatter(x = \"underlier\", y = \"value0\" ,source = df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.renderers.GlyphRenderer\">GlyphRenderer</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'2e95efde-306d-4736-bc26-a0740a414a88', <span id=\"95a5b022-921c-4fb9-bfff-9264ffcdc6e4\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">data_source&nbsp;=&nbsp;ColumnDataSource(id='72de66e4-6700-4ffb-877b-d8da4a3151eb', ...),</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">glyph&nbsp;=&nbsp;Circle(id='bc7fbaa8-c827-4a6c-b2f1-090d41712805', ...),</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hover_glyph&nbsp;=&nbsp;None,</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">level&nbsp;=&nbsp;'glyph',</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted&nbsp;=&nbsp;False,</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted_glyph&nbsp;=&nbsp;None,</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">nonselection_glyph&nbsp;=&nbsp;Circle(id='8bcb31ee-77b4-4b61-bb1b-43410dc5011c', ...),</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">selection_glyph&nbsp;=&nbsp;None,</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">view&nbsp;=&nbsp;CDSView(id='0398292b-81c8-448b-81bb-633565e42bb9', ...),</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range_name&nbsp;=&nbsp;'default',</div></div><div class=\"698dbe44-107b-4bf2-97ac-7398250b48b3\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range_name&nbsp;=&nbsp;'default')</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"95a5b022-921c-4fb9-bfff-9264ffcdc6e4\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"698dbe44-107b-4bf2-97ac-7398250b48b3\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "GlyphRenderer(id='2e95efde-306d-4736-bc26-a0740a414a88', ...)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.scatter(x = \"underlier\", y = \"value1\" ,source = df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"edff66a2-73bc-4c0e-8647-98a2b4f72c85\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"4b1a1760-ba9f-4486-a4b2-0a1dcaa249e7\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"e36f177d-00f1-4d6b-9594-628946e8cd91\",\"type\":\"PanTool\"},{\"attributes\":{\"data_source\":{\"id\":\"72de66e4-6700-4ffb-877b-d8da4a3151eb\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"bc7fbaa8-c827-4a6c-b2f1-090d41712805\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"8bcb31ee-77b4-4b61-bb1b-43410dc5011c\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"0398292b-81c8-448b-81bb-633565e42bb9\",\"type\":\"CDSView\"}},\"id\":\"2e95efde-306d-4736-bc26-a0740a414a88\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"cef9efdd-7bb1-4a08-acc5-e2fea7ede399\",\"type\":\"HelpTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"underlier\"},\"y\":{\"field\":\"value0\"}},\"id\":\"e2406238-b7b7-4d11-9c94-db89fc1879f5\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"3872ef7a-f28a-4a11-96ae-b48e16a17c9c\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"8df33cf9-89a4-41b2-8996-ff6db26c1dd1\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"index\",\"underlier\",\"value0\",\"value1\"],\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],\"underlier\":{\"__ndarray__\":\"AAAAAAAAJEAAAAAAAAA0QAAAAAAAAD5AAAAAAAAAREAAAAAAAABJQAAAAAAAAE5AAAAAAACAUUAAAAAAAABUQAAAAAAAgFZAAAAAAAAAWUAAAAAAAIBbQAAAAAAAAF5AAAAAAABAYEAAAAAAAIBhQAAAAAAAwGJAAAAAAAAAZEAAAAAAAEBlQAAAAAAAgGZAAAAAAADAZ0A=\",\"dtype\":\"float64\",\"shape\":[19]},\"value0\":{\"__ndarray__\":\"AAAAAB/vGMAAAAAAPcgWwAAAAMBccRTAAAAAwD/1EcAAAADAB88OwAAAAADZfAnAAAAAAOp5A8AAAADA8+36vwAAAIAn0O2/AAAAADDbvr8AAACAhrbmPwAAAAAnuP0/AAAAwM7iCEAAAAAAxHQRQAAAAEAheBZAAAAAIH17G0AAAACAbT8gQAAAAMAbwSJAAAAAwMlCJUA=\",\"dtype\":\"float64\",\"shape\":[19]},\"value1\":{\"__ndarray__\":\"AAAAQMDVCcAAAABADcAWwAAAACBrSiDAAAAA4GA6JcAAAABgEC4qwAAAAIB7Ii/AAAAAAKIMMsAAAAAABog0wAAAAOBpAzfAAAAAIBZ9OcAAAAAANfY7wAAAAADHZj7AAAAAgEBqQMAAAACAHaFBwAAAAKD610LAAAAAgNcORMAAAACAtEVFwAAAAECRfEbAAAAAQG6zR8A=\",\"dtype\":\"float64\",\"shape\":[19]}}},\"id\":\"794ce520-b858-49d8-9348-64c2020aa2ca\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"6d2aea15-764b-4777-b25a-339d3b48456b\",\"type\":\"ResetTool\"},{\"attributes\":{\"formatter\":{\"id\":\"6e0f71f4-df4d-45c1-bdf6-f9fa0c933fa7\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"63324673-a648-41ca-99d3-6d1ae0bb1271\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"9d9ad5b7-c58e-4004-9ff6-6002835f5c95\",\"type\":\"BasicTicker\"}},\"id\":\"b68c8019-b0ae-4679-88f4-bb0d35e0dbe1\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"794ce520-b858-49d8-9348-64c2020aa2ca\",\"type\":\"ColumnDataSource\"}},\"id\":\"93a5a994-f1a9-4efb-80ce-15947321a003\",\"type\":\"CDSView\"},{\"attributes\":{\"source\":{\"id\":\"72de66e4-6700-4ffb-877b-d8da4a3151eb\",\"type\":\"ColumnDataSource\"}},\"id\":\"0398292b-81c8-448b-81bb-633565e42bb9\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"188bb996-0bcb-4af2-bde3-000d7a2567a7\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"e36f177d-00f1-4d6b-9594-628946e8cd91\",\"type\":\"PanTool\"},{\"id\":\"8df33cf9-89a4-41b2-8996-ff6db26c1dd1\",\"type\":\"WheelZoomTool\"},{\"id\":\"88c7ed60-f4ae-44b3-b0a0-ba096e61418f\",\"type\":\"BoxZoomTool\"},{\"id\":\"188bb996-0bcb-4af2-bde3-000d7a2567a7\",\"type\":\"SaveTool\"},{\"id\":\"6d2aea15-764b-4777-b25a-339d3b48456b\",\"type\":\"ResetTool\"},{\"id\":\"cef9efdd-7bb1-4a08-acc5-e2fea7ede399\",\"type\":\"HelpTool\"}]},\"id\":\"8d44db29-cfd3-44f5-a3ce-543e022ba68d\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"6e0f71f4-df4d-45c1-bdf6-f9fa0c933fa7\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"fa4cea5f-ff2b-4ce9-b0dc-578862bf7697\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null},\"id\":\"58958699-ca3a-4821-b0fb-59721133a177\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"794ce520-b858-49d8-9348-64c2020aa2ca\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"e2406238-b7b7-4d11-9c94-db89fc1879f5\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"5f59a90c-ab1e-4299-9f62-adfc82cea8d4\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"93a5a994-f1a9-4efb-80ce-15947321a003\",\"type\":\"CDSView\"}},\"id\":\"3be9dad8-566a-43e7-b819-0f3603725886\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"9d9ad5b7-c58e-4004-9ff6-6002835f5c95\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"63324673-a648-41ca-99d3-6d1ae0bb1271\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"9d9ad5b7-c58e-4004-9ff6-6002835f5c95\",\"type\":\"BasicTicker\"}},\"id\":\"770a1c7a-a215-445e-8eaa-9428ab6cc217\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"index\",\"underlier\",\"value0\",\"value1\"],\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],\"underlier\":{\"__ndarray__\":\"AAAAAAAAJEAAAAAAAAA0QAAAAAAAAD5AAAAAAAAAREAAAAAAAABJQAAAAAAAAE5AAAAAAACAUUAAAAAAAABUQAAAAAAAgFZAAAAAAAAAWUAAAAAAAIBbQAAAAAAAAF5AAAAAAABAYEAAAAAAAIBhQAAAAAAAwGJAAAAAAAAAZEAAAAAAAEBlQAAAAAAAgGZAAAAAAADAZ0A=\",\"dtype\":\"float64\",\"shape\":[19]},\"value0\":{\"__ndarray__\":\"AAAAAB/vGMAAAAAAPcgWwAAAAMBccRTAAAAAwD/1EcAAAADAB88OwAAAAADZfAnAAAAAAOp5A8AAAADA8+36vwAAAIAn0O2/AAAAADDbvr8AAACAhrbmPwAAAAAnuP0/AAAAwM7iCEAAAAAAxHQRQAAAAEAheBZAAAAAIH17G0AAAACAbT8gQAAAAMAbwSJAAAAAwMlCJUA=\",\"dtype\":\"float64\",\"shape\":[19]},\"value1\":{\"__ndarray__\":\"AAAAQMDVCcAAAABADcAWwAAAACBrSiDAAAAA4GA6JcAAAABgEC4qwAAAAIB7Ii/AAAAAAKIMMsAAAAAABog0wAAAAOBpAzfAAAAAIBZ9OcAAAAAANfY7wAAAAADHZj7AAAAAgEBqQMAAAACAHaFBwAAAAKD610LAAAAAgNcORMAAAACAtEVFwAAAAECRfEbAAAAAQG6zR8A=\",\"dtype\":\"float64\",\"shape\":[19]}}},\"id\":\"72de66e4-6700-4ffb-877b-d8da4a3151eb\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"4f272421-c478-4ff8-9bb7-fc2c8c16af88\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"8f449a0f-883c-4c51-a223-bc1a09f6cde9\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"c766b7ae-2a13-47db-98bb-3a781cdf2818\",\"type\":\"BoxAnnotation\"}},\"id\":\"88c7ed60-f4ae-44b3-b0a0-ba096e61418f\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"c766b7ae-2a13-47db-98bb-3a781cdf2818\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"underlier\"},\"y\":{\"field\":\"value0\"}},\"id\":\"5f59a90c-ab1e-4299-9f62-adfc82cea8d4\",\"type\":\"Circle\"},{\"attributes\":{\"formatter\":{\"id\":\"4f272421-c478-4ff8-9bb7-fc2c8c16af88\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"63324673-a648-41ca-99d3-6d1ae0bb1271\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5edd54e4-772b-4042-b478-b873bb6f1603\",\"type\":\"BasicTicker\"}},\"id\":\"8fbf187a-c7b8-4fae-b791-a12556590568\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null},\"id\":\"d14e0a45-782b-4281-a282-271e017779df\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"underlier\"},\"y\":{\"field\":\"value1\"}},\"id\":\"8bcb31ee-77b4-4b61-bb1b-43410dc5011c\",\"type\":\"Circle\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"underlier\"},\"y\":{\"field\":\"value1\"}},\"id\":\"bc7fbaa8-c827-4a6c-b2f1-090d41712805\",\"type\":\"Circle\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"63324673-a648-41ca-99d3-6d1ae0bb1271\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5edd54e4-772b-4042-b478-b873bb6f1603\",\"type\":\"BasicTicker\"}},\"id\":\"e397f280-5203-42e0-ab55-d2a86d97134e\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"b68c8019-b0ae-4679-88f4-bb0d35e0dbe1\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"8fbf187a-c7b8-4fae-b791-a12556590568\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"b68c8019-b0ae-4679-88f4-bb0d35e0dbe1\",\"type\":\"LinearAxis\"},{\"id\":\"770a1c7a-a215-445e-8eaa-9428ab6cc217\",\"type\":\"Grid\"},{\"id\":\"8fbf187a-c7b8-4fae-b791-a12556590568\",\"type\":\"LinearAxis\"},{\"id\":\"e397f280-5203-42e0-ab55-d2a86d97134e\",\"type\":\"Grid\"},{\"id\":\"c766b7ae-2a13-47db-98bb-3a781cdf2818\",\"type\":\"BoxAnnotation\"},{\"id\":\"3be9dad8-566a-43e7-b819-0f3603725886\",\"type\":\"GlyphRenderer\"},{\"id\":\"2e95efde-306d-4736-bc26-a0740a414a88\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"8f449a0f-883c-4c51-a223-bc1a09f6cde9\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"8d44db29-cfd3-44f5-a3ce-543e022ba68d\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"d14e0a45-782b-4281-a282-271e017779df\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"fa4cea5f-ff2b-4ce9-b0dc-578862bf7697\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"58958699-ca3a-4821-b0fb-59721133a177\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"3872ef7a-f28a-4a11-96ae-b48e16a17c9c\",\"type\":\"LinearScale\"}},\"id\":\"63324673-a648-41ca-99d3-6d1ae0bb1271\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"5edd54e4-772b-4042-b478-b873bb6f1603\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"63324673-a648-41ca-99d3-6d1ae0bb1271\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.13\"}};\n",
       "  var render_items = [{\"docid\":\"4b1a1760-ba9f-4486-a4b2-0a1dcaa249e7\",\"elementid\":\"edff66a2-73bc-4c0e-8647-98a2b4f72c85\",\"modelid\":\"63324673-a648-41ca-99d3-6d1ae0bb1271\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "63324673-a648-41ca-99d3-6d1ae0bb1271"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cartpole_env.agent.brain.model.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考（書籍のoriginal Environment）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV)  # 実行する課題を設定\n",
    "        num_states = self.env.observation_space.shape[0]  # 課題の状態数4を取得\n",
    "        num_actions = self.env.action_space.n  # CartPoleの行動（右に左に押す）の2を取得\n",
    "        self.agent = Agent(num_states, num_actions)  # 環境内で行動するAgentを生成\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        '''実行'''\n",
    "        episode_10_list = np.zeros(10)  # 10試行分の立ち続けたstep数を格納し、平均ステップ数を出力に利用\n",
    "        complete_episodes = 0  # 195step以上連続で立ち続けた試行数\n",
    "        episode_final = False  # 最後の試行フラグ\n",
    "        frames = []  # 最後の試行を動画にするために画像を格納する変数\n",
    "\n",
    "        for episode in range(NUM_EPISODES):  # 最大試行数分繰り返す\n",
    "            observation = self.env.reset()  # 環境の初期化\n",
    "\n",
    "            state = observation  # 観測をそのまま状態sとして使用\n",
    "            state = torch.from_numpy(state).type(\n",
    "                torch.FloatTensor)  # NumPy変数をPyTorchのテンソルに変換\n",
    "            state = torch.unsqueeze(state, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "            for step in range(MAX_STEPS):  # 1エピソードのループ\n",
    "\n",
    "                if episode_final is True:  # 最終試行ではframesに各時刻の画像を追加していく\n",
    "                    frames.append(self.env.render(mode='rgb_array'))\n",
    "\n",
    "                action = self.agent.get_action(state, episode)  # 行動を求める\n",
    "\n",
    "                # 行動a_tの実行により、s_{t+1}とdoneフラグを求める\n",
    "                # actionから.item()を指定して、中身を取り出す\n",
    "                observation_next, _, done, _ = self.env.step(\n",
    "                    action.item())  # rewardとinfoは使わないので_にする\n",
    "\n",
    "                # 報酬を与える。さらにepisodeの終了評価と、state_nextを設定する\n",
    "                if done:  # ステップ数が200経過するか、一定角度以上傾くとdoneはtrueになる\n",
    "                    state_next = None  # 次の状態はないので、Noneを格納\n",
    "\n",
    "                    # 直近10episodeの立てたstep数リストに追加\n",
    "                    episode_10_list = np.hstack(\n",
    "                        (episode_10_list[1:], step + 1))\n",
    "\n",
    "                    if step < 195:\n",
    "                        reward = torch.FloatTensor(\n",
    "                            [-1.0])  # 途中でこけたら罰則として報酬-1を与える\n",
    "                        complete_episodes = 0  # 連続成功記録をリセット\n",
    "                    else:\n",
    "                        reward = torch.FloatTensor([1.0])  # 立ったまま終了時は報酬1を与える\n",
    "                        complete_episodes = complete_episodes + 1  # 連続記録を更新\n",
    "                else:\n",
    "                    reward = torch.FloatTensor([0.0])  # 普段は報酬0\n",
    "                    state_next = observation_next  # 観測をそのまま状態とする\n",
    "                    state_next = torch.from_numpy(state_next).type(\n",
    "                        torch.FloatTensor)  # numpy変数をPyTorchのテンソルに変換\n",
    "                    state_next = torch.unsqueeze(state_next, 0)  # size 4をsize 1x4に変換\n",
    "\n",
    "                # メモリに経験を追加\n",
    "                self.agent.memorize(state, action, state_next, reward)\n",
    "\n",
    "                # Experience ReplayでQ関数を更新する\n",
    "                self.agent.update_q_function()\n",
    "\n",
    "                # 観測の更新\n",
    "                state = state_next\n",
    "\n",
    "                # 終了時の処理\n",
    "                if done:\n",
    "                    print('%d Episode: Finished after %d steps：10試行の平均step数 = %.1lf' % (\n",
    "                        episode, step + 1, episode_10_list.mean()))\n",
    "                    break\n",
    "\n",
    "            if episode_final is True:\n",
    "                # 動画を保存と描画\n",
    "                display_frames_as_gif(frames)\n",
    "                break\n",
    "\n",
    "            # 10連続で200step経ち続けたら成功\n",
    "            if complete_episodes >= 10:\n",
    "                print('10回連続成功')\n",
    "                episode_final = True  # 次の試行を描画を行う最終試行とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main クラス\n",
    "cartpole_env = Environment()\n",
    "cartpole_env.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base2]",
   "language": "python",
   "name": "conda-env-base2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "209px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "671px",
    "left": "0px",
    "right": "1669.6px",
    "top": "110px",
    "width": "194px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
