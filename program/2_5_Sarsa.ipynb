{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.5 Sarsaで迷路を攻略**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用するパッケージの宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期位置での迷路の様子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1352fc860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 図を描く大きさと、図の変数名を宣言\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 赤い壁を描く\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 状態を示す文字S0～S8を描く\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 描画範囲の設定と目盛りを消す設定\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom='off', top='off',\n",
    "                labelbottom='off', right='off', left='off', labelleft='off')\n",
    "\n",
    "# 現在地S0に緑丸を描画する\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期の方策を決定するパラメータtheta_0を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行は状態0～7、列は移動方向で↑、→、↓、←を表す\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8はゴールなので、方策はなし\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方策パラメータtheta_0をランダム方策piに変換する関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''単純に割合を計算する'''\n",
    "\n",
    "    [m, n] = theta.shape  # thetaの行列サイズを取得\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 割合の計算\n",
    "\n",
    "    pi = np.nan_to_num(pi)  # nanを0に変換\n",
    "\n",
    "    return pi\n",
    "\n",
    "# ランダム行動方策pi_0を求める\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期の行動価値関数Qを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 行動価値とはあるノードであるアクションを取る、と決めた場合のその状態の「現在価値」\n",
    "- 初期Qは動ける方向に乱数を割り振った行動価値関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a, b] = theta_0.shape  # 行と列の数をa, bに格納\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta0をすることで要素ごとに掛け算をし、Qの壁方向の値がnanになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan,  1.,  1., nan],\n",
       "       [nan,  1., nan,  1.],\n",
       "       [nan, nan,  1.,  1.],\n",
       "       [ 1.,  1.,  1., nan],\n",
       "       [nan, nan,  1.,  1.],\n",
       "       [ 1., nan, nan, nan],\n",
       "       [ 1., nan, nan, nan],\n",
       "       [ 1.,  1., nan, nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan, 0.27699327, 0.30443931,        nan],\n",
       "       [       nan, 0.35551303,        nan, 0.53667904],\n",
       "       [       nan,        nan, 0.73827459, 0.45148956],\n",
       "       [0.592643  , 0.24435403, 0.98120932,        nan],\n",
       "       [       nan,        nan, 0.47428497, 0.66186123],\n",
       "       [0.06778662,        nan,        nan,        nan],\n",
       "       [0.47372454,        nan,        nan,        nan],\n",
       "       [0.40752349, 0.4656436 ,        nan,        nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ε-greedy法を実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_3のpolicy gradientではその時の行動方策piに基づいた確率的な時間推進していたが、$\\epsilon$-greedyでは\n",
    "- 確率$1-\\epsilon$でQの各行の最大成分のところに飛ぶ\n",
    "- 確率$\\epsilon$で行動方策に基づいたランダムな時間推進をする\n",
    "\n",
    "という構図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "    # 行動を決める\n",
    "    if np.random.rand() < epsilon:\n",
    "        # εの確率でランダムに動く\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # Qの最大値の行動を採用する\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 行動をindexに\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a]  # 行動aの方向\n",
    "\n",
    "    # 行動から次の状態を決める\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3  # 上に移動するときは状態の数字が3小さくなる\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1  # 右に移動するときは状態の数字が1大きくなる\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3  # 下に移動するときは状態の数字が3大きくなる\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1  # 左に移動するときは状態の数字が1小さくなる\n",
    "\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsaによる行動価値関数Qの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "\n",
    "    if s_next == 8:  # ゴールした場合\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "\n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsaで迷路を解く関数の定義、状態と行動の履歴および更新したQを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # スタート地点\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 初期の行動\n",
    "    s_a_history = [[0, np.nan]]  # エージェントの移動を記録するリスト\n",
    "\n",
    "    while (1):  # ゴールするまでループ\n",
    "        a = a_next  # 行動更新\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 現在の状態（つまり一番最後なのでindex=-1）に行動を代入\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 次の状態を格納\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 次の状態を代入。行動はまだ分からないのでnanにしておく\n",
    "\n",
    "        # 報酬を与え,　次の行動を求めます\n",
    "        if s_next == 8:\n",
    "            r = 1  # ゴールにたどり着いたなら報酬を与える\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 次の行動a_nextを求めます。\n",
    "\n",
    "        # 価値関数を更新\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "\n",
    "        # 終了判定\n",
    "        if s_next == 8:  # ゴール地点なら終了\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 何をやっているかの解明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1  # 学習率\n",
    "gamma = 0.9  # 時間割引率\n",
    "epsilon = 0.5  # ε-greedy法の初期値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = pi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0  # スタート地点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のアクションを求める方式は$\\epsilon$-greedyであればsarsaなのかQ探索なのかに依らない："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_next = get_action(s, Q, epsilon, pi)  # 初期の行動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_a_history = [[0, np.nan]]  # エージェントの移動を記録するリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_action(s, Q, epsilon, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### この辺はpolicy gradientと同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a_next  # 行動更新a\n",
    "\n",
    "s_a_history[-1][1] = a\n",
    "# 現在の状態（つまり一番最後なのでindex=-1）に行動を代入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "# 次の状態を格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_a_history.append([s_next, np.nan])\n",
    "# 次の状態を代入。行動はまだ分からないのでnanにしておく\n",
    "\n",
    "# 報酬を与え,　次の行動を求めます\n",
    "if s_next == 8:\n",
    "    r = 1  # ゴールにたどり着いたなら報酬を与える\n",
    "    a_next = np.nan\n",
    "else:\n",
    "    r = 0\n",
    "    a_next = get_action(s_next, Q, epsilon, pi)\n",
    "    # 次の行動a_nextを求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan, 0.27699327, 0.41171092,        nan],\n",
       "       [       nan, 0.35551303,        nan, 0.53667904],\n",
       "       [       nan,        nan, 0.73827459, 0.45148956],\n",
       "       [0.592643  , 0.24435403, 0.98120932,        nan],\n",
       "       [       nan,        nan, 0.47428497, 0.66186123],\n",
       "       [0.06778662,        nan,        nan,        nan],\n",
       "       [0.47372454,        nan,        nan,        nan],\n",
       "       [0.40752349, 0.4656436 ,        nan,        nan]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将来ペイオフの割引現在価値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35823903722934414"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma * Q[s_next , a_next]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(s,a)におけるクーポンはゼロなので将来価値から計算される現在価値は"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35823903722934414"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r + gamma * Q[s_next, a_next]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仮置きされている(s,a)における現在価値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7260373270267131"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[s,a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 両者のミスマッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36779828979736895"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r + gamma * Q[s_next , a_next] - Q[s,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アップデート後の$Q[s,a]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892574980469762"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[s, a] + eta * (r + gamma * Q[s_next , a_next] - Q[s,a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsaで迷路を解く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エピソード:1\n",
      "0.704251765132853\n",
      "迷路を解くのにかかったステップ数は124です\n",
      "エピソード:2\n",
      "0.19737619362030778\n",
      "迷路を解くのにかかったステップ数は44です\n",
      "エピソード:3\n",
      "0.08269799465012478\n",
      "迷路を解くのにかかったステップ数は8です\n",
      "エピソード:4\n",
      "0.06971792755124312\n",
      "迷路を解くのにかかったステップ数は14です\n",
      "エピソード:5\n",
      "0.04575073737334845\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:6\n",
      "0.04519608490254595\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:7\n",
      "0.044561886315888144\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:8\n",
      "0.04388240823338868\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:9\n",
      "0.043437930063012276\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:10\n",
      "0.04297407066567971\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:11\n",
      "0.04248472820205679\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:12\n",
      "0.04196479411401821\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:13\n",
      "0.04141024389524939\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:14\n",
      "0.04081815830221458\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:15\n",
      "0.04018669402016806\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:16\n",
      "0.039515018904181964\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:17\n",
      "0.0388032237066227\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:18\n",
      "0.03805221957024485\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:19\n",
      "0.03726362841665709\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:20\n",
      "0.036439671614053926\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:21\n",
      "0.035583060898559116\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:22\n",
      "0.034696894393445366\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:23\n",
      "0.033784559671818926\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:24\n",
      "0.03284964510062044\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:25\n",
      "0.03189586015293622\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:26\n",
      "0.030926964953039593\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:27\n",
      "0.029946709000400917\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:28\n",
      "0.02895877878511599\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:29\n",
      "0.02796675384119135\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:30\n",
      "0.026974070672104722\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:31\n",
      "0.02598399391362205\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:32\n",
      "0.02499959406261032\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:33\n",
      "0.024023731089845235\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:34\n",
      "0.023059043263310874\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:35\n",
      "0.022107940531115422\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:36\n",
      "0.021172601845834915\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:37\n",
      "0.020254975851552004\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:38\n",
      "0.01935678439850319\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:39\n",
      "0.018479528396059042\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:40\n",
      "0.017624495561160525\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:41\n",
      "0.0167927696651623\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:42\n",
      "0.015985240926395194\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:43\n",
      "0.015202617238022964\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:44\n",
      "0.014445435960538378\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:45\n",
      "0.013714076045201584\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:46\n",
      "0.01300877028877645\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:47\n",
      "0.012329617550978722\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:48\n",
      "0.011676594794167938\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:49\n",
      "0.011049568830064027\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:50\n",
      "0.010448307680761326\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:51\n",
      "0.00987249148122693\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:52\n",
      "0.009321722867929427\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:53\n",
      "0.008795536813478222\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:54\n",
      "0.008293409880295033\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:55\n",
      "0.007814768877606904\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:56\n",
      "0.007358998915604986\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:57\n",
      "0.006925450858626059\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:58\n",
      "0.006513448185853199\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:59\n",
      "0.006122293273455481\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:60\n",
      "0.005751273116418321\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:61\n",
      "0.005399664511715363\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:62\n",
      "0.005066738727040554\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:63\n",
      "0.00475176568117075\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:64\n",
      "0.004454017663277687\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:65\n",
      "0.004172772619223664\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:66\n",
      "0.003907317033158275\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:67\n",
      "0.0036569484326439694\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:68\n",
      "0.003420977545149473\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:69\n",
      "0.003198730133104455\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:70\n",
      "0.0029895485338851113\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:71\n",
      "0.002792792930096488\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:72\n",
      "0.002607842374425795\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:73\n",
      "0.0024340955921426932\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:74\n",
      "0.0022709715830845356\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:75\n",
      "0.0021179100436793385\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:76\n",
      "0.001974371628282512\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:77\n",
      "0.0018398380678052995\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:78\n",
      "0.001713812162352668\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:79\n",
      "0.00159581766334993\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:80\n",
      "0.0014853990594303479\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:81\n",
      "0.0013821212792012316\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:82\n",
      "0.0012855693229020249\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:83\n",
      "0.0011953478339042922\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:84\n",
      "0.0011110806200103074\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:85\n",
      "0.0010324101335602576\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:86\n",
      "0.0009589969184761182\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:87\n",
      "0.0008905190315365852\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:88\n",
      "0.0008266714444102874\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:89\n",
      "0.0007671654322571886\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:90\n",
      "0.0007117279540402865\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:91\n",
      "0.0006601010290842035\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:92\n",
      "0.0006120411138516024\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:93\n",
      "0.000567318482394441\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:94\n",
      "0.0005257166134645663\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:95\n",
      "0.0004870315868448216\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:96\n",
      "0.0004510714910677116\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:97\n",
      "0.0004176558443411693\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:98\n",
      "0.0003866150301853333\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:99\n",
      "0.0003577897489930315\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "エピソード:100\n",
      "0.0003310304864836411\n",
      "迷路を解くのにかかったステップ数は4です\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1  # 学習率\n",
    "gamma = 0.9  # 時間割引率\n",
    "epsilon = 0.5  # ε-greedy法の初期値\n",
    "v = np.nanmax(Q, axis=1)  # 状態ごとに価値の最大値を求める\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:  # is_continueがFalseになるまで繰り返す\n",
    "    print(\"エピソード:\" + str(episode))\n",
    "\n",
    "    # ε-greedyの値を少しずつ小さくする\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # Sarsaで迷路を解き、移動した履歴と更新したQを求める\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 状態価値の変化\n",
    "    new_v = np.nanmax(Q, axis=1)  # 状態ごとに価値の最大値を求める\n",
    "    print(np.sum(np.abs(new_v - v)))  # 状態価値の変化を出力\n",
    "    v = new_v\n",
    "\n",
    "    print(\"迷路を解くのにかかったステップ数は\" + str(len(s_a_history) - 1) + \"です\")\n",
    "\n",
    "    # 100エピソード繰り返す\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 0ae45f1] doing sarsa\n",
      " 2 files changed, 429 insertions(+), 92 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git commit -a -m \"doing sarsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "226px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
